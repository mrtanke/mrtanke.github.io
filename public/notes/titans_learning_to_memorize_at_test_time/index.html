<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Titans: Learning to Memorize at Test Time | Home</title><meta name=keywords content><meta name=description content="Paper-reading notes: Titans"><meta name=author content><link rel=canonical href=https://my-blog-alpha-vert.vercel.app/notes/titans_learning_to_memorize_at_test_time/><link crossorigin=anonymous href=/assets/css/stylesheet.9bb7abd44394c0e0d2cecd8ad4322626054cd3f5709a6d890d5a408efaf1fa90.css integrity="sha256-m7er1EOUwODSzs2K1DImJgVM0/Vwmm2JDVpAjvrx+pA=" rel="preload stylesheet" as=style><link rel=icon href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=icon type=image/png sizes=16x16 href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=icon type=image/png sizes=32x32 href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=apple-touch-icon href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=mask-icon href=https://my-blog-alpha-vert.vercel.app/selfile.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://my-blog-alpha-vert.vercel.app/notes/titans_learning_to_memorize_at_test_time/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css integrity crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js integrity crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js integrity crossorigin=anonymous></script><script defer>document.addEventListener("DOMContentLoaded",function(){typeof renderMathInElement=="function"&&renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1,ignoredTags:["script","noscript","style","textarea","pre","code"]})})</script><style>ul#menu .tag-button{background:0 0;border:none;padding:0;margin:0;font-weight:500;color:inherit;cursor:pointer;text-decoration:none;opacity:.95;display:inline-block}ul#menu .tag-button:hover{text-decoration:underline}ul#menu .tag-button.active{text-decoration:underline;font-weight:600}body.is-home .post-entry{display:none}body.is-home .page-footer .pagination{display:none}</style><script>(function(){function e(){const e=location.pathname.replace(/\/+/g,"/");return e==="/"||e===""||e==="/index.html"}e()&&document.body.classList.add("is-home"),document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("menu");if(!e)return;if(e.querySelector(".tag-button"))return;const n=["Notes","Thoughts","Projects"],t={Notes:"/notes/",Thoughts:"/thoughts/",Projects:"/projects/"};n.forEach(n=>{const o=document.createElement("li"),s=document.createElement("a");s.className="tag-button",s.href=t[n],s.textContent=n,location.pathname.toLowerCase().startsWith(t[n])&&s.classList.add("active"),o.appendChild(s),e.appendChild(o)})})})()</script><meta property="og:url" content="https://my-blog-alpha-vert.vercel.app/notes/titans_learning_to_memorize_at_test_time/"><meta property="og:site_name" content="Home"><meta property="og:title" content="Titans: Learning to Memorize at Test Time"><meta property="og:description" content="Paper-reading notes: Titans"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="notes"><meta property="article:published_time" content="2025-11-26T08:42:17+00:00"><meta property="article:modified_time" content="2025-11-26T08:42:17+00:00"><meta property="og:image" content="https://my-blog-alpha-vert.vercel.app/notes/titans_learning_to_memorize_at_test_time/image.png"><meta property="og:image" content="https://my-blog-alpha-vert.vercel.app/notes/titans_learning_to_memorize_at_test_time/image_1.png"><meta property="og:image" content="https://my-blog-alpha-vert.vercel.app/notes/titans_learning_to_memorize_at_test_time/image_2.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://my-blog-alpha-vert.vercel.app/notes/titans_learning_to_memorize_at_test_time/image.png"><meta name=twitter:title content="Titans: Learning to Memorize at Test Time"><meta name=twitter:description content="Paper-reading notes: Titans"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Notes","item":"https://my-blog-alpha-vert.vercel.app/notes/"},{"@type":"ListItem","position":2,"name":"Titans: Learning to Memorize at Test Time","item":"https://my-blog-alpha-vert.vercel.app/notes/titans_learning_to_memorize_at_test_time/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Titans: Learning to Memorize at Test Time","name":"Titans: Learning to Memorize at Test Time","description":"Paper-reading notes: Titans","keywords":[],"articleBody":"1. Introduction Transformers provide accurate short-term memory through attention but suffer from quadratic cost and fixed context window limits. Linear Transformers and modern linear RNNs improve efficiency but must compress all history into fixed-size states, which causes memory overflow and poor long-range recall.v\nHuman memory has separate short-term and long-term systems; existing architectures usually miss long-term memory that can adapt at test time.\nKey question: How to design a neural long-term memory that can learn, forget, and recall information over extremely long contexts efficiently?\nTitans introduce:\nA neural long-term memory (LMM) that updates weights at test time. Titans architectures that integrate LMM with attention and persistent memory. 2. Method 2.1 Neural Long-term Memory (LMM) LMM treats learning as memorizing past tokens into its parameters during test time.\nUses a surprise metric: the gradient of the associative memory loss with respect to the input, larger gradient → more “surprising” token → more memorable.\nThe memory update dynamics are:\nMemory stores Associative key–value pairs using a loss**:** $$ \\ell = |M_{t-1}(k_t) - v_t|_2^2 $$\nwhere $k_t = x_t W_K$ and $v_t = x_t W_V$.\nSurprise gradient: $$ g_t = \\nabla_{M_{t-1}}\\ell $$\nSurprise momentum: $$ S_t = \\eta_t S_{t-1} - \\theta_t g_t $$\nCombined using a data-dependent decay $\\eta_t$ and learning rate $\\theta_t$ Forget gate: $\\alpha_t \\in [0,1]$ $\\alpha_t \\to 1$ ⇒ forget history $\\alpha_t \\to 0$ ⇒ retain history Memory update: $$ M_t = (1 - \\alpha_t) M_{t-1} + S_t $$\nRetrieval: $$ y_t = M_t(q_t) $$\n2.2 Parallelizable Training LMM training is equivalent to mini-batch gradient descent with momentum + weight decay.\nThe authors show this can be reformulated into operations using matmuls + associative scan, enabling fast, hardware-friendly parallel training.\n2.3 Persistent Memory A small set of fixed, learnable vectors prepended to the sequence.\nPurpose:\nStore task-level knowledge (not input-dependent). Counteract attention bias toward early tokens. Equivalent to data-independent attention keys/values (as shown by FFN→softmax reinterpretation). 2.4 Titans Architectures (Three Variants) All Titans have three components:\nShort-term memory = attention (sliding window attention) Long-term memory = LMM Persistent memory = learned prefix Variants:\nMAC — Memory as Context: Retrieve memory → concatenate with persistent memory → feed into attention → Best long-context performance.\nMAG — Memory as Gate: Combine Sliding Window Attention output and memory output via gating. MAL — Memory as Layer: Sequential: LMM → Sliding Window Attention. Simpler but weaker performance. 3. Novelty 3.1. Memory Structure Titans introduce a long-term memory (LMM) that can learn and store information across millions of tokens. This memory is a deep, learnable module, not just a matrix or KV-cache. Three designs (MAL) show flexible ways to combine long-term memory with short-term attention. 3.2. Memory Update LMM learns during inference, using a simple idea: more surprising tokens are written more strongly. Updates use momentum (past surprise + current surprise) for stability. A forget gate decides how much old memory to remove to avoid overflow. 3.3. Memory Retrieval LMM learns a key → value mapping, acting like a smart, compressing KV-cache. The model retrieves long-term information when needed and mixes it with short-term attention (SWA). 4. More Details 4.1. What is M? M is a learnable function (an MLP) that stores long-term information.\n$$ M : R^d \\rightarrow R^d $$\nIt takes a vector (key or query) and outputs another vector (a “memory value”).\nYou can think of M as a neural dictionary:\ninput = address output = content Except this dictionary learns at test time, and compresses many past tokens into a fixed-sized neural network.\nM is a single neural function used for both retrieving (q→memory output) and storing (k→v); it learns key–value associations during update and returns long-term recall results during retrieval.\n4.2. What does M do during RETRIEVAL? Retrieval input: query\n$$ q_t = x_t W_Q $$\nMemory returns:\n$$ y^{(LMM)}_t = M(q_t) $$\nMeaning:\n“Given this query, what long-term knowledge have we stored that matches it?”\nSo during retrieval:\nM behaves as a lookup function q = the question M(q) = the answer from long-term memory Here, all the knowledge is compressed inside the MLP weights.\n4.3. What does M do during UPDATE? Update input: key\n$$ k_t = x_t W_K,\\qquad v_t = x_t W_V $$\nMemory tries to learn the mapping:\n$$ M(k_t) \\approx v_t $$\nError:\n$$ \\ell = | M(k_t) - v_t |^2 $$\nGradient:\n$$ g_t = \\nabla_{M} \\ell $$\nMemory update:\n$$ M \\leftarrow M - \\theta g_t $$\nMeaning:\n“Given this key, the correct value should be v. Update yourself so you can remember this in the future.”\nSo during update:\nM behaves as a learnable associative memory k = the address v = the content M learns: k → v This is exactly like writing to a KV-cache — except the cache is a learnable neural network that can compress, forget, and generalize.\n4.4. What role does M play? Role 1: long-term storage M learns from (k,v) pairs:\n$$ M(k) \\approx v $$\nThis is how it stores information.\nRole 2: long-term retrieval M responds to queries:\n$$ M(q) = \\text{long-term memory output} $$\nThis is how it retrieves information.\nWhy both? Because:\nKeys write into memory Queries read from memory Both must use the same space so they match Keys are used to WRITE because they represent stable addresses for storing information (like a KV-cache).\nQueries are used to READ because they represent the current question the model is asking the memory.\nTitans follow the same logic as attention: K = address, V = content, Q = question.\n","wordCount":"916","inLanguage":"en","image":"https://my-blog-alpha-vert.vercel.app/notes/titans_learning_to_memorize_at_test_time/image.png","datePublished":"2025-11-26T08:42:17Z","dateModified":"2025-11-26T08:42:17Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://my-blog-alpha-vert.vercel.app/notes/titans_learning_to_memorize_at_test_time/"},"publisher":{"@type":"Organization","name":"Home","logo":{"@type":"ImageObject","url":"https://my-blog-alpha-vert.vercel.app/selfile.png"}}}</script></head><body id=top><script>window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://my-blog-alpha-vert.vercel.app/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches></div></div><ul id=menu><li><a class=tag-button href=https://my-blog-alpha-vert.vercel.app/notes/><span class=active>Notes</span></a></li><li><a class=tag-button href=https://my-blog-alpha-vert.vercel.app/thoughts/><span>Thoughts</span></a></li><li><a class=tag-button href=https://my-blog-alpha-vert.vercel.app/projects/><span>Projects</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://my-blog-alpha-vert.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=/notes/>Notes</a></div><h1 class="post-title entry-hint-parent">Titans: Learning to Memorize at Test Time</h1><div class=post-description>Paper-reading notes: Titans</div><div class=post-meta><span title='2025-11-26 08:42:17 +0000 +0000'>November 26, 2025</span>&nbsp;·&nbsp;<span>916 words</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-introduction aria-label="1. Introduction">1. Introduction</a></li><li><a href=#2-method aria-label="2. Method">2. Method</a><ul><li><a href=#21-neural-long-term-memory-lmm aria-label="2.1 Neural Long-term Memory (LMM)">2.1 Neural Long-term Memory (LMM)</a></li><li><a href=#22-parallelizable-training aria-label="2.2 Parallelizable Training">2.2 Parallelizable Training</a></li><li><a href=#23-persistent-memory aria-label="2.3 Persistent Memory">2.3 Persistent Memory</a></li><li><a href=#24-titans-architectures-three-variants aria-label="2.4 Titans Architectures (Three Variants)">2.4 Titans Architectures (Three Variants)</a></li></ul></li><li><a href=#3-novelty aria-label="3. Novelty">3. Novelty</a><ul><li><a href=#31-memory-structure aria-label="3.1. Memory Structure">3.1. Memory Structure</a></li><li><a href=#32-memory-update aria-label="3.2. Memory Update">3.2. Memory Update</a></li><li><a href=#33-memory-retrieval aria-label="3.3. Memory Retrieval">3.3. Memory Retrieval</a></li></ul></li><li><a href=#4-more-details aria-label="4. More Details">4. More Details</a><ul><li><a href=#41-what-is-m aria-label="4.1. What is M?">4.1. What is M?</a></li><li><a href=#42-what-does-m-do-during-retrieval aria-label="4.2. What does M do during RETRIEVAL?">4.2. What does M do during RETRIEVAL?</a></li><li><a href=#43-what-does-m-do-during-update aria-label="4.3. What does M do during UPDATE?">4.3. What does M do during UPDATE?</a></li><li><a href=#44-what-role-does-m-play aria-label="4.4. What role does M play?">4.4. What role does M play?</a><ul><li><a href=#role-1-long-term-storage aria-label="Role 1: long-term storage">Role 1: long-term storage</a></li><li><a href=#role-2-long-term-retrieval aria-label="Role 2: long-term retrieval">Role 2: long-term retrieval</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><h1 id=1-introduction><strong>1. Introduction</strong><a hidden class=anchor aria-hidden=true href=#1-introduction>#</a></h1><p>Transformers provide <strong>accurate short-term memory</strong> through attention but suffer from <strong>quadratic cost</strong> and <strong>fixed context window</strong> limits. Linear Transformers and modern linear RNNs improve efficiency but must <strong>compress all history into fixed-size states</strong>, which causes <strong>memory overflow and poor long-range recall</strong>.v</p><p>Human memory has <strong>separate short-term and long-term systems</strong>; existing architectures usually miss long-term memory that can adapt at test time.</p><p>Key question: <em>How to design a neural long-term memory that can learn, forget, and recall information over extremely long contexts efficiently?</em></p><p>Titans introduce:</p><ul><li>A <strong>neural long-term memory (LMM)</strong> that updates weights at test time.</li><li>Titans architectures that integrate LMM with attention and <strong>persistent memory</strong>.</li></ul><h1 id=2-method><strong>2. Method</strong><a hidden class=anchor aria-hidden=true href=#2-method>#</a></h1><h2 id=21-neural-long-term-memory-lmm><strong>2.1 Neural Long-term Memory (LMM)</strong><a hidden class=anchor aria-hidden=true href=#21-neural-long-term-memory-lmm>#</a></h2><p>LMM treats learning as <strong>memorizing past tokens into its parameters</strong> during test time.</p><p>Uses a <strong>surprise metric</strong>: the gradient of the associative memory loss with respect to the input, larger gradient → more “surprising” token → more memorable.</p><p>The memory update dynamics are:</p><ol><li>Memory stores <strong>Associative key–value pairs</strong> using a loss**:**</li></ol><p>$$
\ell = |M_{t-1}(k_t) - v_t|_2^2
$$</p><p>where $k_t = x_t W_K$ and $v_t = x_t W_V$.</p><ol><li><strong>Surprise gradient:</strong></li></ol><p>$$
g_t = \nabla_{M_{t-1}}\ell
$$</p><ol><li><strong>Surprise momentum:</strong></li></ol><p>$$
S_t = \eta_t S_{t-1} - \theta_t g_t
$$</p><ul><li>Combined using a data-dependent decay $\eta_t$ and learning rate $\theta_t$<ul><li><strong>Forget gate: $\alpha_t \in [0,1]$</strong><ul><li>$\alpha_t \to 1$ ⇒ forget history</li><li>$\alpha_t \to 0$ ⇒ retain history</li></ul></li></ul></li></ul><ol><li><strong>Memory update:</strong></li></ol><p>$$
M_t = (1 - \alpha_t) M_{t-1} + S_t
$$</p><ol><li><strong>Retrieval:</strong></li></ol><p>$$
y_t = M_t(q_t)
$$</p><h2 id=22-parallelizable-training><strong>2.2 Parallelizable Training</strong><a hidden class=anchor aria-hidden=true href=#22-parallelizable-training>#</a></h2><p>LMM training is equivalent to <strong>mini-batch gradient descent with momentum + weight decay</strong>.</p><p>The authors show this can be reformulated into operations using <strong>matmuls + associative scan</strong>, enabling <strong>fast, hardware-friendly parallel training</strong>.</p><h2 id=23-persistent-memory><strong>2.3 Persistent Memory</strong><a hidden class=anchor aria-hidden=true href=#23-persistent-memory>#</a></h2><p>A small set of <strong>fixed, learnable vectors</strong> prepended to the sequence.</p><p>Purpose:</p><ul><li>Store <strong>task-level knowledge</strong> (not input-dependent).</li><li>Counteract attention bias toward early tokens.</li><li>Equivalent to <strong>data-independent attention keys/values</strong> (as shown by FFN→softmax reinterpretation).</li></ul><h2 id=24-titans-architectures-three-variants><strong>2.4 Titans Architectures (Three Variants)</strong><a hidden class=anchor aria-hidden=true href=#24-titans-architectures-three-variants>#</a></h2><p>All Titans have <strong>three components</strong>:</p><ol><li>Short-term memory = attention (sliding window attention)</li><li><strong>Long-term memory = LMM</strong></li><li>Persistent memory = learned prefix</li></ol><p>Variants:</p><ul><li><strong>MAC — Memory as Context:</strong></li></ul><p>Retrieve memory → concatenate with persistent memory → feed into attention → Best long-context performance.</p><p><img alt=image.png loading=lazy src=/notes/titans_learning_to_memorize_at_test_time/image.png></p><ul><li><strong>MAG — Memory as Gate:</strong> Combine Sliding Window Attention output and memory output via gating.</li></ul><p><img alt=image.png loading=lazy src=/notes/titans_learning_to_memorize_at_test_time/image_1.png></p><ul><li><strong>MAL — Memory as Layer:</strong> Sequential: LMM → Sliding Window Attention. Simpler but weaker performance.</li></ul><p><img alt=image.png loading=lazy src=/notes/titans_learning_to_memorize_at_test_time/image_2.png></p><h1 id=3-novelty><strong>3. Novelty</strong><a hidden class=anchor aria-hidden=true href=#3-novelty>#</a></h1><h2 id=31-memory-structure><strong>3.1. Memory Structure</strong><a hidden class=anchor aria-hidden=true href=#31-memory-structure>#</a></h2><ul><li>Titans introduce a <strong>long-term memory (LMM)</strong> that can learn and store information across <strong>millions of tokens</strong>.</li><li>This memory is a <strong>deep, learnable module</strong>, not just a matrix or KV-cache.</li><li>Three designs (MAL) show flexible ways to combine long-term memory with short-term attention.</li></ul><h2 id=32-memory-update><strong>3.2. Memory Update</strong><a hidden class=anchor aria-hidden=true href=#32-memory-update>#</a></h2><ul><li>LMM learns <strong>during inference</strong>, using a simple idea: <strong>more surprising tokens are written more strongly.</strong></li><li>Updates use <strong>momentum</strong> (past surprise + current surprise) for stability.</li><li>A <strong>forget gate</strong> decides how much old memory to remove to avoid overflow.</li></ul><h2 id=33-memory-retrieval><strong>3.3. Memory Retrieval</strong><a hidden class=anchor aria-hidden=true href=#33-memory-retrieval>#</a></h2><ul><li>LMM learns a <strong>key → value</strong> mapping, acting like a smart, compressing KV-cache.</li><li>The model retrieves long-term information when needed and mixes it with short-term attention (SWA).</li></ul><h1 id=4-more-details>4. More Details<a hidden class=anchor aria-hidden=true href=#4-more-details>#</a></h1><h2 id=41-what-is-m><strong>4.1. What is M?</strong><a hidden class=anchor aria-hidden=true href=#41-what-is-m>#</a></h2><p><strong>M is a learnable function</strong> (an MLP) that stores long-term information.</p><p>$$
M : R^d \rightarrow R^d
$$</p><p>It takes a vector (key or query) and outputs another vector (a “memory value”).</p><p>You can think of M as a <strong>neural dictionary</strong>:</p><ul><li>input = <strong>address</strong></li><li>output = <strong>content</strong></li></ul><p>Except this dictionary <strong>learns at test time</strong>, and <strong>compresses</strong> many past tokens into a fixed-sized neural network.</p><aside><p>M is a single neural function used for both <strong>retrieving</strong> (q→memory output) and <strong>storing</strong> (k→v); it learns key–value associations during update and returns long-term recall results during retrieval.</p></aside><h2 id=42-what-does-m-do-during-retrieval><strong>4.2. What does M do during RETRIEVAL?</strong><a hidden class=anchor aria-hidden=true href=#42-what-does-m-do-during-retrieval>#</a></h2><p>Retrieval input: <strong>query</strong></p><p>$$
q_t = x_t W_Q
$$</p><p>Memory returns:</p><p>$$
y^{(LMM)}_t = M(q_t)
$$</p><p><strong>Meaning:</strong></p><blockquote><p>“Given this query, what long-term knowledge have we stored that matches it?”</p></blockquote><p>So during retrieval:</p><ul><li>M behaves as a <strong>lookup function</strong></li><li>q = the question</li><li>M(q) = the answer from long-term memory</li></ul><p>Here, all the knowledge is <strong>compressed inside the MLP weights</strong>.</p><h2 id=43-what-does-m-do-during-update><strong>4.3. What does M do during UPDATE?</strong><a hidden class=anchor aria-hidden=true href=#43-what-does-m-do-during-update>#</a></h2><p>Update input: <strong>key</strong></p><p>$$
k_t = x_t W_K,\qquad v_t = x_t W_V
$$</p><p>Memory tries to <strong>learn the mapping</strong>:</p><p>$$
M(k_t) \approx v_t
$$</p><p>Error:</p><p>$$
\ell = | M(k_t) - v_t |^2
$$</p><p>Gradient:</p><p>$$
g_t = \nabla_{M} \ell
$$</p><p>Memory update:</p><p>$$
M \leftarrow M - \theta g_t
$$</p><p><strong>Meaning:</strong></p><blockquote><p>“Given this key, the correct value should be v. Update yourself so you can remember this in the future.”</p></blockquote><p>So during update:</p><ul><li>M behaves as a <strong>learnable associative memory</strong></li><li>k = the address</li><li>v = the content</li><li>M learns: k → v</li></ul><p>This is exactly like writing to a KV-cache — except the cache is a <strong>learnable neural network</strong> that can compress, forget, and generalize.</p><h2 id=44-what-role-does-m-play><strong>4.4. What role does M play?</strong><a hidden class=anchor aria-hidden=true href=#44-what-role-does-m-play>#</a></h2><h3 id=role-1-long-term-storage><strong>Role 1: long-term storage</strong><a hidden class=anchor aria-hidden=true href=#role-1-long-term-storage>#</a></h3><p>M learns from (k,v) pairs:</p><p>$$
M(k) \approx v
$$</p><p>This is how it <strong>stores</strong> information.</p><h3 id=role-2-long-term-retrieval><strong>Role 2: long-term retrieval</strong><a hidden class=anchor aria-hidden=true href=#role-2-long-term-retrieval>#</a></h3><p>M responds to queries:</p><p>$$
M(q) = \text{long-term memory output}
$$</p><p>This is how it <strong>retrieves</strong> information.</p><p><strong>Why both?</strong> Because:</p><ul><li><strong>Keys</strong> write into memory</li><li><strong>Queries</strong> read from memory</li><li>Both must use the <strong>same space</strong> so they match</li></ul><aside><p>Keys are used to WRITE because they represent stable addresses for storing information (like a KV-cache).</p><p>Queries are used to READ because they represent the current question the model is asking the memory.</p><p>Titans follow the same logic as attention: <strong>K = address, V = content, Q = question</strong>.</p></aside></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>