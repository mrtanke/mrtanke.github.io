<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>FNet: Mixing Tokens with Fourier Transforms | Home</title><meta name=keywords content><meta name=description content="Paper-reading notes: FNet"><meta name=author content><link rel=canonical href=https://my-blog-alpha-vert.vercel.app/notes/fnet_mixing_tokens_with_fourier_transforms/><link crossorigin=anonymous href=/assets/css/stylesheet.9bb7abd44394c0e0d2cecd8ad4322626054cd3f5709a6d890d5a408efaf1fa90.css integrity="sha256-m7er1EOUwODSzs2K1DImJgVM0/Vwmm2JDVpAjvrx+pA=" rel="preload stylesheet" as=style><link rel=icon href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=icon type=image/png sizes=16x16 href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=icon type=image/png sizes=32x32 href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=apple-touch-icon href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=mask-icon href=https://my-blog-alpha-vert.vercel.app/selfile.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://my-blog-alpha-vert.vercel.app/notes/fnet_mixing_tokens_with_fourier_transforms/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css integrity crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js integrity crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js integrity crossorigin=anonymous></script><script defer>document.addEventListener("DOMContentLoaded",function(){typeof renderMathInElement=="function"&&renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1,ignoredTags:["script","noscript","style","textarea","pre","code"]})})</script><style>ul#menu .tag-button{background:0 0;border:none;padding:0;margin:0;font-weight:500;color:inherit;cursor:pointer;text-decoration:none;opacity:.95;display:inline-block}ul#menu .tag-button:hover{text-decoration:underline}ul#menu .tag-button.active{text-decoration:underline;font-weight:600}body.is-home .post-entry{display:none}body.is-home .page-footer .pagination{display:none}</style><script>(function(){function e(){const e=location.pathname.replace(/\/+/g,"/");return e==="/"||e===""||e==="/index.html"}e()&&document.body.classList.add("is-home"),document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("menu");if(!e)return;if(e.querySelector(".tag-button"))return;const n=["Notes","Thoughts","Projects"],t={Notes:"/notes/",Thoughts:"/thoughts/",Projects:"/projects/"};n.forEach(n=>{const o=document.createElement("li"),s=document.createElement("a");s.className="tag-button",s.href=t[n],s.textContent=n,location.pathname.toLowerCase().startsWith(t[n])&&s.classList.add("active"),o.appendChild(s),e.appendChild(o)})})})()</script><meta property="og:url" content="https://my-blog-alpha-vert.vercel.app/notes/fnet_mixing_tokens_with_fourier_transforms/"><meta property="og:site_name" content="Home"><meta property="og:title" content="FNet: Mixing Tokens with Fourier Transforms"><meta property="og:description" content="Paper-reading notes: FNet"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="notes"><meta property="article:published_time" content="2025-12-05T15:11:32+00:00"><meta property="article:modified_time" content="2025-12-05T15:11:32+00:00"><meta property="og:image" content="https://my-blog-alpha-vert.vercel.app/notes/fnet_mixing_tokens_with_fourier_transforms/image.png"><meta property="og:image" content="https://my-blog-alpha-vert.vercel.app/notes/fnet_mixing_tokens_with_fourier_transforms/image_1.png"><meta property="og:image" content="https://my-blog-alpha-vert.vercel.app/notes/fnet_mixing_tokens_with_fourier_transforms/image_2.png"><meta property="og:image" content="https://my-blog-alpha-vert.vercel.app/notes/fnet_mixing_tokens_with_fourier_transforms/image_3.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://my-blog-alpha-vert.vercel.app/notes/fnet_mixing_tokens_with_fourier_transforms/image.png"><meta name=twitter:title content="FNet: Mixing Tokens with Fourier Transforms"><meta name=twitter:description content="Paper-reading notes: FNet"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Notes","item":"https://my-blog-alpha-vert.vercel.app/notes/"},{"@type":"ListItem","position":2,"name":"FNet: Mixing Tokens with Fourier Transforms","item":"https://my-blog-alpha-vert.vercel.app/notes/fnet_mixing_tokens_with_fourier_transforms/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"FNet: Mixing Tokens with Fourier Transforms","name":"FNet: Mixing Tokens with Fourier Transforms","description":"Paper-reading notes: FNet","keywords":[],"articleBody":"1. Method 1.1. Replace self-attention with a 2D Fourier Transform FNet removes the entire self-attention sublayer from Transformer encoders. Instead, each layer performs a 2D Discrete Fourier Transform (DFT) on the input:\n$$ y = \\Re\\left(F_{\\text{seq}}(F_h(x))\\right) $$\n$F_{\\text{seq}}$: 1D DFT along the sequence length $F_h$: 1D DFT along the hidden dimension The discrete Fourier Transform (DFT) is defined by the formula: Thus, no Q/K/V, no dot-products, and no softmax are computed.\n1.2. Simple Transformer-style architecture Each encoder block contains:\nFourier mixing sublayer (parameter-free) Feed-forward network (FFN) Residual + LayerNorm (same as BERT) The model uses the same word/type/position embeddings as BERT, but position embeddings are technically unnecessary because the Fourier basis already encodes position.\nFNet architecture with N encoder blocks.\nFNet includes position embeddings only to make experiments directly comparable with BERT. The authors wanted to keep everything the same except replacing self-attention with Fourier Transform.\n1.3. Computational efficiency The FFT has complexity: $O(n \\log n d)$ because of FFT (Fast Fourier Transform).\nCompared to self-attention: $O(n^2 d)$\nThis yields major speedups:\n80% faster training on GPUs, 70% faster on TPUs, Much faster for long sequences (LRA benchmark). 2. Novelty 2.1. First model to fully replace attention with Fourier mixing Previous works used Fourier features to approximate attention (e.g., Performer).\nFNet is the first to:\nRemove self-attention entirely and use a fixed, unparameterized Fourier Transform as the token-mixing mechanism.\nThe mixing weights come purely from:\n$$ e^{-2\\pi i nk / N} $$\nand not from learned Q·K projections.\n2.2. Demonstrates that structured linear mixing can rival attention A surprising empirical finding:\nFNet reaches 92–97% of BERT’s accuracy on GLUE Despite having zero learned parameters in its mixing layer This suggests:\nAttention is not always the main source of performance;\nhigh-quality token mixing + FFN may be sufficient for many NLP tasks.\n2.3. Superior long-sequence scalability On the Long-Range Arena (LRA) benchmark:\nFNet matches the accuracy of the strongest models But is faster and more memory-efficient than Performer, Linformer, and other efficient Transformers This shows a new path:\nInstead of approximating attention, one can replace it with a simpler mathematical transform.\n2.4. Extremely good small-model efficiency For smaller models, FNet and Linear mixing form the Pareto frontier for speed–accuracy (Fig. 2).\nBecause Fourier mixing is parameter-free:\nSmaller memory footprint High stability during training Better deployment potential on edge devices 3. Why is DFT a mixing operation like attention? Because:\n$$ X_k = \\sum_{n=0}^{N-1} w_{kn} \\cdot x_n $$\nWhere:\n$$ w_{kn} = \\cos(2\\pi nk / N) $$\nThis is EXACTLY what attention does:\n$$ y_i = \\sum_j W_{ij} \\cdot x_j $$\nThe only difference:\nMechanism Weights ( W ) Attention Learned from Q·K Fourier / DFT Fixed sine/cosine patterns Both compute:\nOutput token = weighted sum of all input tokens\nTherefore both are global mixing layers.\n4. Summary Table of Time Complexities ","wordCount":"470","inLanguage":"en","image":"https://my-blog-alpha-vert.vercel.app/notes/fnet_mixing_tokens_with_fourier_transforms/image.png","datePublished":"2025-12-05T15:11:32Z","dateModified":"2025-12-05T15:11:32Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://my-blog-alpha-vert.vercel.app/notes/fnet_mixing_tokens_with_fourier_transforms/"},"publisher":{"@type":"Organization","name":"Home","logo":{"@type":"ImageObject","url":"https://my-blog-alpha-vert.vercel.app/selfile.png"}}}</script></head><body id=top><script>window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://my-blog-alpha-vert.vercel.app/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches></div></div><ul id=menu><li><a class=tag-button href=https://my-blog-alpha-vert.vercel.app/notes/><span class=active>Notes</span></a></li><li><a class=tag-button href=https://my-blog-alpha-vert.vercel.app/thoughts/><span>Thoughts</span></a></li><li><a class=tag-button href=https://my-blog-alpha-vert.vercel.app/projects/><span>Projects</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://my-blog-alpha-vert.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=/notes/>Notes</a></div><h1 class="post-title entry-hint-parent">FNet: Mixing Tokens with Fourier Transforms</h1><div class=post-description>Paper-reading notes: FNet</div><div class=post-meta><span title='2025-12-05 15:11:32 +0000 +0000'>December 5, 2025</span>&nbsp;·&nbsp;<span>470 words</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#1-method aria-label="1. Method">1. Method</a><ul><ul><li><a href=#11-replace-self-attention-with-a-2d-fourier-transform aria-label="1.1. Replace self-attention with a 2D Fourier Transform">1.1. Replace self-attention with a 2D Fourier Transform</a></li><li><a href=#12-simple-transformer-style-architecture aria-label="1.2. Simple Transformer-style architecture">1.2. Simple Transformer-style architecture</a></li><li><a href=#13-computational-efficiency aria-label="1.3. Computational efficiency">1.3. Computational efficiency</a></li></ul></ul></li><li><a href=#2-novelty aria-label="2. Novelty">2. Novelty</a><ul><ul><li><a href=#21-first-model-to-fully-replace-attention-with-fourier-mixing aria-label="2.1. First model to fully replace attention with Fourier mixing">2.1. First model to fully replace attention with Fourier mixing</a></li><li><a href=#22-demonstrates-that-structured-linear-mixing-can-rival-attention aria-label="2.2. Demonstrates that structured linear mixing can rival attention">2.2. Demonstrates that structured linear mixing can rival attention</a></li><li><a href=#23-superior-long-sequence-scalability aria-label="2.3. Superior long-sequence scalability">2.3. Superior long-sequence scalability</a></li><li><a href=#24-extremely-good-small-model-efficiency aria-label="2.4. Extremely good small-model efficiency">2.4. Extremely good small-model efficiency</a></li></ul></ul></li><li><a href=#3-why-is-dft-a-mixing-operation-like-attention aria-label="3. Why is DFT a mixing operation like attention?">3. Why is DFT a mixing operation like attention?</a></li><li><a href=#4-summary-table-of-time-complexities aria-label="4. Summary Table of Time Complexities">4. Summary Table of Time Complexities</a></li></ul></div></details></div><div class=post-content><h1 id=1-method><strong>1. Method</strong><a hidden class=anchor aria-hidden=true href=#1-method>#</a></h1><h3 id=11-replace-self-attention-with-a-2d-fourier-transform><strong>1.1. Replace self-attention with a 2D Fourier Transform</strong><a hidden class=anchor aria-hidden=true href=#11-replace-self-attention-with-a-2d-fourier-transform>#</a></h3><p>FNet removes the entire self-attention sublayer from <strong>Transformer encoders</strong>. Instead, each layer performs a <strong>2D Discrete Fourier Transform (DFT)</strong> on the input:</p><p>$$
y = \Re\left(F_{\text{seq}}(F_h(x))\right)
$$</p><ul><li>$F_{\text{seq}}$: 1D DFT along the <strong>sequence length</strong></li><li>$F_h$: 1D DFT along the <strong>hidden dimension</strong></li><li>The <strong>discrete Fourier Transform (DFT)</strong> is defined by the formula:</li></ul><p><img alt=image.png loading=lazy src=/notes/fnet_mixing_tokens_with_fourier_transforms/image.png></p><p>Thus, <strong>no Q/K/V</strong>, <strong>no dot-products</strong>, and <strong>no softmax</strong> are computed.</p><h3 id=12-simple-transformer-style-architecture><strong>1.2. Simple Transformer-style architecture</strong><a hidden class=anchor aria-hidden=true href=#12-simple-transformer-style-architecture>#</a></h3><p>Each encoder block contains:</p><ol><li><strong>Fourier mixing sublayer</strong> (parameter-free)</li><li><strong>Feed-forward network (FFN)</strong></li><li>Residual + LayerNorm (same as BERT)</li></ol><p>The model uses the same word/type/position embeddings as BERT, but position embeddings are technically unnecessary because the Fourier basis already encodes position.</p><p><img alt="FNet architecture with N encoder blocks." loading=lazy src=/notes/fnet_mixing_tokens_with_fourier_transforms/image_1.png></p><p>FNet architecture with N encoder blocks.</p><aside><p><strong>FNet includes position embeddings only to make experiments directly comparable with BERT.</strong> The authors wanted to keep everything the same except replacing self-attention with Fourier Transform.</p></aside><h3 id=13-computational-efficiency><strong>1.3. Computational efficiency</strong><a hidden class=anchor aria-hidden=true href=#13-computational-efficiency>#</a></h3><p>The FFT has complexity: $O(n \log n d)$ because of FFT (Fast Fourier Transform).</p><p>Compared to self-attention: $O(n^2 d)$</p><p>This yields major speedups:</p><ul><li><strong>80% faster training on GPUs</strong>,</li><li><strong>70% faster on TPUs</strong>,</li><li><strong>Much faster for long sequences</strong> (LRA benchmark).</li></ul><h1 id=2-novelty><strong>2. Novelty</strong><a hidden class=anchor aria-hidden=true href=#2-novelty>#</a></h1><h3 id=21-first-model-to-fully-replace-attention-with-fourier-mixing><strong>2.1. First model to fully replace attention with Fourier mixing</strong><a hidden class=anchor aria-hidden=true href=#21-first-model-to-fully-replace-attention-with-fourier-mixing>#</a></h3><p>Previous works used Fourier features to approximate attention (e.g., Performer).</p><p>FNet is the first to:</p><blockquote><p>Remove self-attention entirely and use a fixed, unparameterized Fourier Transform as the token-mixing mechanism.</p></blockquote><p>The mixing weights come purely from:</p><p>$$
e^{-2\pi i nk / N}
$$</p><p>and not from learned Q·K projections.</p><h3 id=22-demonstrates-that-structured-linear-mixing-can-rival-attention><strong>2.2. Demonstrates that structured linear mixing can rival attention</strong><a hidden class=anchor aria-hidden=true href=#22-demonstrates-that-structured-linear-mixing-can-rival-attention>#</a></h3><p>A surprising empirical finding:</p><ul><li>FNet reaches <strong>92–97% of BERT’s accuracy</strong> on GLUE</li><li>Despite having <strong>zero learned parameters</strong> in its mixing layer</li></ul><p>This suggests:</p><blockquote><p>Attention is not always the main source of performance;</p><p>high-quality token mixing + FFN may be sufficient for many NLP tasks.</p></blockquote><h3 id=23-superior-long-sequence-scalability><strong>2.3. Superior long-sequence scalability</strong><a hidden class=anchor aria-hidden=true href=#23-superior-long-sequence-scalability>#</a></h3><p>On the Long-Range Arena (LRA) benchmark:</p><ul><li>FNet matches the <strong>accuracy</strong> of the strongest models</li><li>But is <strong>faster and more memory-efficient</strong> than Performer, Linformer, and other efficient Transformers</li></ul><p>This shows a new path:</p><blockquote><p>Instead of approximating attention, one can replace it with a simpler mathematical transform.</p></blockquote><h3 id=24-extremely-good-small-model-efficiency><strong>2.4. Extremely good small-model efficiency</strong><a hidden class=anchor aria-hidden=true href=#24-extremely-good-small-model-efficiency>#</a></h3><p>For smaller models, FNet and Linear mixing form the <strong>Pareto frontier</strong> for speed–accuracy (Fig. 2).</p><p>Because Fourier mixing is parameter-free:</p><ul><li>Smaller memory footprint</li><li>High stability during training</li><li>Better deployment potential on edge devices</li></ul><h1 id=3-why-is-dft-a-mixing-operation-like-attention><strong>3. Why is DFT a mixing operation like attention?</strong><a hidden class=anchor aria-hidden=true href=#3-why-is-dft-a-mixing-operation-like-attention>#</a></h1><p>Because:</p><p>$$
X_k = \sum_{n=0}^{N-1} w_{kn} \cdot x_n
$$</p><p>Where:</p><p>$$
w_{kn} = \cos(2\pi nk / N)
$$</p><p>This is EXACTLY what attention does:</p><p>$$
y_i = \sum_j W_{ij} \cdot x_j
$$</p><p><strong>The only difference:</strong></p><table><thead><tr><th>Mechanism</th><th>Weights ( W )</th></tr></thead><tbody><tr><td>Attention</td><td>Learned from Q·K</td></tr><tr><td>Fourier / DFT</td><td>Fixed sine/cosine patterns</td></tr></tbody></table><p>Both compute:</p><p><strong>Output token = weighted sum of all input tokens</strong></p><p>Therefore both are <strong>global mixing layers</strong>.</p><h1 id=4-summary-table-of-time-complexities>4. Summary Table of Time Complexities<a hidden class=anchor aria-hidden=true href=#4-summary-table-of-time-complexities>#</a></h1><p><img alt=image.png loading=lazy src=/notes/fnet_mixing_tokens_with_fourier_transforms/image_2.png></p><p><img alt=image.png loading=lazy src=/notes/fnet_mixing_tokens_with_fourier_transforms/image_3.png></p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>