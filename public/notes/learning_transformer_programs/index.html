<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Learning Transformer Programs | Home</title><meta name=keywords content><meta name=description content="Paper-reading notes: Learning Transformer Programs"><meta name=author content><link rel=canonical href=https://my-blog-alpha-vert.vercel.app/notes/learning_transformer_programs/><link crossorigin=anonymous href=/assets/css/stylesheet.9bb7abd44394c0e0d2cecd8ad4322626054cd3f5709a6d890d5a408efaf1fa90.css integrity="sha256-m7er1EOUwODSzs2K1DImJgVM0/Vwmm2JDVpAjvrx+pA=" rel="preload stylesheet" as=style><link rel=icon href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=icon type=image/png sizes=16x16 href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=icon type=image/png sizes=32x32 href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=apple-touch-icon href=https://my-blog-alpha-vert.vercel.app/selfile.png><link rel=mask-icon href=https://my-blog-alpha-vert.vercel.app/selfile.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://my-blog-alpha-vert.vercel.app/notes/learning_transformer_programs/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.css integrity crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/katex.min.js integrity crossorigin=anonymous></script><script defer src=https://cdn.jsdelivr.net/npm/katex@0.16.8/dist/contrib/auto-render.min.js integrity crossorigin=anonymous></script><script defer>document.addEventListener("DOMContentLoaded",function(){typeof renderMathInElement=="function"&&renderMathInElement(document.body,{delimiters:[{left:"$$",right:"$$",display:!0},{left:"\\[",right:"\\]",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1}],throwOnError:!1,ignoredTags:["script","noscript","style","textarea","pre","code"]})})</script><style>ul#menu .tag-button{background:0 0;border:none;padding:0;margin:0;font-weight:500;color:inherit;cursor:pointer;text-decoration:none;opacity:.95;display:inline-block}ul#menu .tag-button:hover{text-decoration:underline}ul#menu .tag-button.active{text-decoration:underline;font-weight:600}body.is-home .post-entry{display:none}body.is-home .page-footer .pagination{display:none}</style><script>(function(){function e(){const e=location.pathname.replace(/\/+/g,"/");return e==="/"||e===""||e==="/index.html"}e()&&document.body.classList.add("is-home"),document.addEventListener("DOMContentLoaded",function(){const e=document.getElementById("menu");if(!e)return;if(e.querySelector(".tag-button"))return;const n=["Notes","Thoughts","Projects"],t={Notes:"/notes/",Thoughts:"/thoughts/",Projects:"/projects/"};n.forEach(n=>{const o=document.createElement("li"),s=document.createElement("a");s.className="tag-button",s.href=t[n],s.textContent=n,location.pathname.toLowerCase().startsWith(t[n])&&s.classList.add("active"),o.appendChild(s),e.appendChild(o)})})})()</script><meta property="og:url" content="https://my-blog-alpha-vert.vercel.app/notes/learning_transformer_programs/"><meta property="og:site_name" content="Home"><meta property="og:title" content="Learning Transformer Programs"><meta property="og:description" content="Paper-reading notes: Learning Transformer Programs"><meta property="og:locale" content="en-us"><meta property="og:type" content="article"><meta property="article:section" content="notes"><meta property="article:published_time" content="2025-12-15T08:38:28+00:00"><meta property="article:modified_time" content="2025-12-15T08:38:28+00:00"><meta property="og:image" content="https://my-blog-alpha-vert.vercel.app/notes/learning_transformer_programs/image.png"><meta property="og:image" content="https://my-blog-alpha-vert.vercel.app/notes/learning_transformer_programs/image_1.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://my-blog-alpha-vert.vercel.app/notes/learning_transformer_programs/image.png"><meta name=twitter:title content="Learning Transformer Programs"><meta name=twitter:description content="Paper-reading notes: Learning Transformer Programs"><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Notes","item":"https://my-blog-alpha-vert.vercel.app/notes/"},{"@type":"ListItem","position":2,"name":"Learning Transformer Programs","item":"https://my-blog-alpha-vert.vercel.app/notes/learning_transformer_programs/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Learning Transformer Programs","name":"Learning Transformer Programs","description":"Paper-reading notes: Learning Transformer Programs","keywords":[],"articleBody":"Problem Modern Transformers are powerful but fundamentally opaque. Even with mechanistic interpretability tools (attention analysis, circuit discovery), understanding what algorithm a trained Transformer implements still requires heavy manual effort and is often incomplete or misleading.\nPrevious work like RASP and Tracr shows that human-written programs can be compiled into Transformers, but not the reverse: we cannot take an arbitrary trained Transformer and reliably recover a faithful, human-readable program.\nCore problem:\nCan we train Transformers so that their learned computation is, by construction, directly convertible into a discrete, interpretable program—without post-hoc reverse engineering?\nThis paper targets intrinsic interpretability, not explanation after the fact.\nMethod The authors propose Transformer Programs:\na restricted Transformer architecture that is trained with gradients but constrained so it can be deterministically decompiled into a RASP-style program.\nThe method has three key ideas:\n1. Disentangled Residual Stream (Program Variables) The residual stream is split into named, orthogonal variables (e.g. tokens, positions, attn_1_output, …). Each attention head reads specific variables (V) and writes a new variable to a fresh slot. This mirrors RASP’s shared tape, but implemented as structured residual slots. 2. Interpretable Attention = select + aggregate Each attention head is constrained to implement: a discrete predicate (which query attends to which key) followed by hard attention (attend to exactly one key). Attention predicates are parameterized as categorical choices, learned with Gumbel-Softmax, then discretized. This makes every head equivalent to a RASP select operator, with aggregation matching aggregate. 3. Discrete Optimization → Program Extraction Training is done with continuous relaxations of discrete choices. After training, the model is fully discretized:\npredicates become if/else rules, attention becomes symbolic selection, MLPs become lookup tables. The entire model is then automatically converted into Python code, functionally identical to the Transformer and debuggable with standard tools.\nExtensions Numerical attention for counting (RASP selector_width) Constrained MLPs as finite lookup tables Learned word embeddings decomposed into categorical variables One-sentence takeaway Instead of explaining black-box Transformers, this paper trains Transformers that can be directly converted into programs, so interpretation becomes reading code—not guessing behavior.\n","wordCount":"339","inLanguage":"en","image":"https://my-blog-alpha-vert.vercel.app/notes/learning_transformer_programs/image.png","datePublished":"2025-12-15T08:38:28Z","dateModified":"2025-12-15T08:38:28Z","mainEntityOfPage":{"@type":"WebPage","@id":"https://my-blog-alpha-vert.vercel.app/notes/learning_transformer_programs/"},"publisher":{"@type":"Organization","name":"Home","logo":{"@type":"ImageObject","url":"https://my-blog-alpha-vert.vercel.app/selfile.png"}}}</script></head><body id=top><script>window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://my-blog-alpha-vert.vercel.app/ accesskey=h title="Home (Alt + H)">Home</a><div class=logo-switches></div></div><ul id=menu><li><a class=tag-button href=https://my-blog-alpha-vert.vercel.app/notes/><span class=active>Notes</span></a></li><li><a class=tag-button href=https://my-blog-alpha-vert.vercel.app/thoughts/><span>Thoughts</span></a></li><li><a class=tag-button href=https://my-blog-alpha-vert.vercel.app/projects/><span>Projects</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://my-blog-alpha-vert.vercel.app/>Home</a>&nbsp;»&nbsp;<a href=/notes/>Notes</a></div><h1 class="post-title entry-hint-parent">Learning Transformer Programs</h1><div class=post-description>Paper-reading notes: Learning Transformer Programs</div><div class=post-meta><span title='2025-12-15 08:38:28 +0000 +0000'>December 15, 2025</span>&nbsp;·&nbsp;<span>339 words</span></div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#problem aria-label=Problem>Problem</a><ul><li><a href=#method aria-label=Method>Method</a><ul><li><a href=#1-disentangled-residual-stream-program-variables aria-label="1. Disentangled Residual Stream (Program Variables)">1. Disentangled Residual Stream (Program Variables)</a></li><li><a href=#2-interpretable-attention--select--aggregate aria-label="2. Interpretable Attention = select + aggregate">2. Interpretable Attention = select + aggregate</a></li><li><a href=#3-discrete-optimization--program-extraction aria-label="3. Discrete Optimization → Program Extraction">3. Discrete Optimization → Program Extraction</a></li><li><a href=#extensions aria-label=Extensions>Extensions</a></li><li><a href=#one-sentence-takeaway aria-label="One-sentence takeaway">One-sentence takeaway</a></li></ul></li></ul></li></ul></div></details></div><div class=post-content><h1 id=problem>Problem<a hidden class=anchor aria-hidden=true href=#problem>#</a></h1><p>Modern Transformers are powerful but <strong>fundamentally opaque</strong>. Even with mechanistic interpretability tools (attention analysis, circuit discovery), understanding <em>what algorithm a trained Transformer implements</em> still requires <strong>heavy manual effort</strong> and is often <strong>incomplete or misleading</strong>.</p><p>Previous work like <strong>RASP</strong> and <strong>Tracr</strong> shows that <strong>human-written programs can be compiled into Transformers</strong>, but <strong>not the reverse</strong>: we cannot take an arbitrary trained Transformer and reliably recover a faithful, human-readable program.</p><p><strong>Core problem:</strong></p><aside><p>Can we train Transformers so that their learned computation is, by construction, directly convertible into a discrete, interpretable program—without post-hoc reverse engineering?</p></aside><p>This paper targets <strong>intrinsic interpretability</strong>, not explanation after the fact.</p><h2 id=method>Method<a hidden class=anchor aria-hidden=true href=#method>#</a></h2><p>The authors propose <strong>Transformer Programs</strong>:</p><aside><p>a restricted Transformer architecture that is trained with gradients but constrained so it can be deterministically decompiled into a RASP-style program.</p></aside><p>The method has three key ideas:</p><h3 id=1-disentangled-residual-stream-program-variables>1. Disentangled Residual Stream (Program Variables)<a hidden class=anchor aria-hidden=true href=#1-disentangled-residual-stream-program-variables>#</a></h3><ul><li>The residual stream is split into <strong>named, orthogonal variables</strong> (e.g. <code>tokens</code>, <code>positions</code>, <code>attn_1_output</code>, …).</li><li>Each attention head <strong>reads specific variables</strong> (V) and <strong>writes a new variable</strong> to a fresh slot.</li><li>This mirrors <strong>RASP’s shared tape</strong>, but implemented as structured residual slots.</li></ul><p><img alt=image.png loading=lazy src=/notes/learning_transformer_programs/image.png></p><h3 id=2-interpretable-attention--select--aggregate>2. Interpretable Attention = <code>select + aggregate</code><a hidden class=anchor aria-hidden=true href=#2-interpretable-attention--select--aggregate>#</a></h3><ul><li>Each attention head is constrained to implement:<ul><li>a <strong>discrete predicate</strong> (<code>which query attends to which key</code>)</li><li>followed by <strong>hard attention</strong> (attend to exactly one key).</li></ul></li><li>Attention predicates are parameterized as <strong>categorical choices</strong>, learned with <strong>Gumbel-Softmax</strong>, then discretized.</li><li>This makes every head equivalent to a <strong>RASP <code>select</code> operator</strong>, with aggregation matching <code>aggregate</code>.</li></ul><h3 id=3-discrete-optimization--program-extraction>3. Discrete Optimization → Program Extraction<a hidden class=anchor aria-hidden=true href=#3-discrete-optimization--program-extraction>#</a></h3><p>Training is done with <strong>continuous relaxations</strong> of discrete choices. After training, the model is <strong>fully discretized</strong>:</p><ul><li>predicates become <code>if/else</code> rules,</li><li>attention becomes symbolic selection,</li><li>MLPs become <strong>lookup tables</strong>.</li></ul><p>The entire model is then <strong>automatically converted into Python code</strong>, functionally identical to the Transformer and debuggable with standard tools.</p><p><img alt=image.png loading=lazy src=/notes/learning_transformer_programs/image_1.png></p><h3 id=extensions>Extensions<a hidden class=anchor aria-hidden=true href=#extensions>#</a></h3><ul><li><strong>Numerical attention</strong> for counting (RASP <code>selector_width</code>)</li><li><strong>Constrained MLPs</strong> as finite lookup tables</li><li>Learned word embeddings decomposed into categorical variables</li></ul><h3 id=one-sentence-takeaway>One-sentence takeaway<a hidden class=anchor aria-hidden=true href=#one-sentence-takeaway>#</a></h3><p>Instead of explaining black-box Transformers, this paper trains Transformers that can be directly converted into programs, so interpretation becomes reading code—not guessing behavior.</p></div><footer class=post-footer><ul class=post-tags></ul></footer></article></main><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>